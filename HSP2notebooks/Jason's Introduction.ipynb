{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/HSP2.png\" />\n",
    "This Jupyter Notebook Copyright 2017 by RESPEC, INC.  All rights reserved.\n",
    "\n",
    "$\\textbf{HSP}^{\\textbf{2}}\\ \\text{and}\\ \\textbf{HSP2}\\ $ Copyright 2017 by RESPEC INC. and released under this [License](LegalInformation/License.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Youtube Video Developed for HSP2 and this Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<iframe width=\"896\" height=\"504\" src=\"https://www.youtube.com/embed/aeLScKsP1Wk?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Python imports  and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import site\n",
    "site.addsitedir(os.getcwd().rsplit('\\\\',1)[0] + '\\\\')  # adds your path to the HSP2 software.\n",
    "\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows    = 18\n",
    "pd.options.display.max_columns = 10\n",
    "pd.options.display.float_format = '{:.2f}'.format  # display 2 digits after the decimal point\n",
    "\n",
    "import HSP2\n",
    "import HSP2tools\n",
    "\n",
    "import qgrid\n",
    "# Tell qgrid to automatically render all DataFrames and Series as qgrids.\n",
    "qgrid.enable()\n",
    "# Disable automatic display so we can display DataFrames in the normal way\n",
    "# qgrid.disable()\n",
    "\n",
    "import matplotlib.pyplot as m_plt\n",
    "%matplotlib inline\n",
    "\n",
    "HSP2tools.reset_tutorial()    # make a new copy of the tutorial's data\n",
    "HSP2tools.versions()          # display version information below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing UCI & WDM Files into HDF5<a id='section1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uciname = os.path.join('TutorialData', 'test10.uci') \n",
    "wdmname = os.path.join('TutorialData', 'test.wdm')\n",
    "\n",
    "unpackedhdfname = os.path.join('TutorialData', 'unpackedtutorial.h5')\n",
    "hdfname = os.path.join('TutorialData', 'Tutorial.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HSP2tools.makeH5()\n",
    "HSP2tools.readUCI(uciname, unpackedhdfname)\n",
    "HSP2tools.ReadWDM(wdmname, unpackedhdfname)\n",
    "!ptrepack {unpackedhdfname}  {hdfname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run $\\textbf{HSP}^\\textbf{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HSP2.run??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HSP2.run(hdfname, saveall=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review simulated hydraulic state variables and fluxes from hdf5 file for Reach 1\n",
    "tsMaster = pd.read_hdf(hdfname, '/RESULTS/RCHRES_R001/HYDR')\n",
    "tsMaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Plot of RCHRES 1 Flow\n",
    "m_plt.figure(figsize=(16,8))\n",
    "m_plt.plot('RO', 'b--', data=tsMaster,   label='Master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creeate a DateFrame, Calculate Summart Stats, and Save for Later\n",
    "columns = ['Master','Run1','Run3', 'Run4']\n",
    "dfStats = pd.DataFrame(columns=columns)\n",
    "dfStats.Master = tsMaster.RO.describe()\n",
    "\n",
    "dfStats.Master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There are Multiple ways we Can Change Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Using HSP2Tools.Fetch and then HSP2Tools.replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaceinfo, df = HSP2tools.fetch(hdfname, 'PERLND', 'PWATER', 'PARAMETERS')\n",
    "replaceinfo, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Value of LZSN\n",
    "df.LZSN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change and Replace using HSP2Tools.replace?? \n",
    "df.LZSN = 12\n",
    "HSP2tools.replace(replaceinfo, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Pandas to Read and Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/PERLND/PWATER/PARAMETERS'\n",
    "df2 = pd.read_hdf(hdfname, datapath)\n",
    "df2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write to HDF\n",
    "df2.LZSN = 8\n",
    "df2.to_hdf(hdfname, '/PERLND/PWATER/PARAMETERS', data_columns=True, format='table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Changed\n",
    "df2 = pd.read_hdf(hdfname, datapath)\n",
    "df2.LZSN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Pandas and Qgrid Functionality to Update Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the dataframe and edit Qgrid directly (e.g., dbl click and change LZSN to 6) then use qgrid_widget.get_changed_df()\n",
    "qgrid_widget = qgrid.QgridWidget(df=df2.T, show_toolbar=True)\n",
    "qgrid_widget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3 = qgrid_widget.get_changed_df()\n",
    "df3.T.to_hdf(hdfname, '/PERLND/PWATER/PARAMETERS', data_columns=True, format='table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Changed\n",
    "df2 = pd.read_hdf(hdfname, datapath)\n",
    "df2.LZSN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use HSPTools.csvReader to Update Paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFile = os.path.join('TutorialData', 'perlnd.csv')\n",
    "pd.read_csv(csvFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use CSV to Update the HDF5 File\n",
    "HSP2tools.csvReader(hdfname, csvFile, 'PERLND', 'PWATER')\n",
    "# verify changed\n",
    "var = ['INFILT','LZSN']\n",
    "pd.read_hdf(hdfname, datapath)[var]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use HSPTools.DoE (Design of Experiment) function to Update Paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How Can we Cange Multiple Parameters and Track Changes\n",
    "# Using the HSP2.DoE approach allows us to create new folders within HDF5 file to document \n",
    "# changes from base and store new results\n",
    "data = [\n",
    " ['1', 'PERLND', 'P001', 'PWATER', 'INFILT',   0.075],\n",
    " ['1', 'PERLND', 'P001', 'PWATER', 'LZSN',         4],\n",
    " ['2', 'PERLND', 'P001', 'PWATER', 'INFILT',    0.30],\n",
    " ['2', 'PERLND', 'P001', 'PWATER', 'LZSN',      12.0]]\n",
    "\n",
    "doe = pd.DataFrame(data, columns=['Run', 'Operation', 'Segment', 'Module', 'Parameter', 'Value'])\n",
    "doe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HSP2.run_DoE(hdfname, 'Sensitivity_LZSN_INFILT', doe, saveall=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire and Calculate Stats on Run 1 & Run 2 and Compare to Master\n",
    "tsRun_1  = pd.read_hdf(hdfname, 'Sensitivity_LZSN_INFILT/RESULTS/RUN1/RCHRES_R001/HYDR')\n",
    "tsRun_2  = pd.read_hdf(hdfname, 'Sensitivity_LZSN_INFILT/RESULTS/RUN2/RCHRES_R001/HYDR')\n",
    "\n",
    "dfStats.Run1 = tsRun_1.RO.describe()\n",
    "dfStats.Run2 = tsRun_2.RO.describe()\n",
    "dfStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_plt.figure(figsize=(16,8))\n",
    "m_plt.plot('RO', 'b--', data=tsMaster,   label='Master')\n",
    "m_plt.plot('RO', 'r',   data=tsRun_1,    label='Run1')\n",
    "m_plt.plot('RO', 'g-',   data=tsRun_2,  label='Run2')\n",
    "m_plt.title('Flow at Reach 1')\n",
    "m_plt.ylabel('Hourly Flow {CFS}')\n",
    "m_plt.legend(loc='best') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample for Monthly Flow\n",
    "m_plt.figure(figsize=(16,8))\n",
    "m_plt.plot('RO', 'b--', data=tsMaster.resample('M').mean(),   label='Master')\n",
    "m_plt.plot('RO', 'r',   data=tsRun_1.resample('M').mean(),    label='Run1')\n",
    "m_plt.plot('RO', 'g-',   data=tsRun_2.resample('M').mean(),  label='Run2')\n",
    "m_plt.title('Flow at Reach 1')\n",
    "m_plt.ylabel('Monthly Flow {CFS}')\n",
    "m_plt.legend(loc='best') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use DoE approach to do a quick sensitivity analysis of LZSN\n",
    "N = 20   # number of runs - generally large such as 1000 or 10,000\n",
    "data = []\n",
    "for r in range(1, N+1):\n",
    "    run = str(r+10)\n",
    "    data.append([run,'PERLND','P001','PWATER','LZSN', 1 + float(np.random.rand(1)) * 15])\n",
    "   \n",
    "doe = pd.DataFrame(data, columns=['Run', 'Operation', 'Segment', 'Module', 'Parameter', 'Value'])\n",
    "doe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HSP2.run_DoE(hdfname, 'P001_LZSN', doe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get paths to all the results for RCHRES\n",
    "keys = ['P001_LZSN/RESULTS/RUN' + str(k+10) + '/RCHRES_R001/HYDR' for k in range(1,N+1)]\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.DataFrame()\n",
    "for k in keys:\n",
    "    colname = k[18:23]\n",
    "    df = pd.read_hdf(hdfname, k)\n",
    "    ts[colname] = df.ROVOL\n",
    "    \n",
    "ts.plot(label = 'simulated volume (ac-ft)',figsize = (18,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ts.describe()\n",
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a time series for the INFILT parameter\n",
    "\n",
    "#### First, create a time series for INFILT and save it in the HDF5 file's /Timeseries directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Constant parameters in HSPF can be replaced by time series in $\\textbf{HSP}^\\textbf{2}$ \n",
    "\n",
    "\n",
    "Some HSPF parameters were optionally allow to vary in time using FLAG and MONTHLY tables. The other HSPF parameters were constants.\n",
    "HSPF used the following algorithm to determine the parameter's value at any time in the simulation when it was allowed to vary:\n",
    "+ First interpolate monthly table values to get daily values. \n",
    "+ The values at timesteps within each day are set to the day's daily value.\n",
    "\n",
    "However, the HSPF Special Functions capability could be used to allow any HSPF parameter to vary over time.\n",
    "\n",
    "This capability to vary any parameter over time is made more integral to $\\textbf{HSP}^\\textbf{2}$.\n",
    "\n",
    "#### IMPLIMENTATION in $\\textbf{HSP}^\\textbf{2}$ \n",
    "\n",
    "Internally, $\\textbf{HSP}^\\textbf{2}$, creates a time series for each parameter over the entire simulation interval at the start of each activity's code. \n",
    "\n",
    "The rules for creating a time series are simple:\n",
    "+ Whenever the EXT_SOURCES table directs a time series with the name of an HSPF parameter (in TMEMN) to the current OPSEQ operation and segment (TVOL and TVOLNO), then this time series will be used in place of the parameter. (Because this is different bahavior than HSP2, a logged message\n",
    "alerts the user whenever this is done.)\n",
    "+ Otherwise, if the flag and monthly table information used by HSPF to allow a parameter to vary over time is found in the $\\textbf{HSP}^\\textbf{2}$ tables, then the HSPF algorithm is used to create a time series over the entire simulation interval.\n",
    "+ Otherwise, this was is constant parameter in HSPF. The constant value found in for the parameter from PARAMETERS table will be used to fill the array.\n",
    "\n",
    "There is no additional performance hit to specify a time series for a parameter since all parameters are already treated as time series internally anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the simulation's GLOBAL data to create a time index for this simulation. The new series must at least contain the simulations start, stop boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdata = pd.read_hdf(hdfname, '/CONTROL/GLOBAL')['Data']\n",
    "gdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The frequency does not need to be at any fixed value - HSP2 will resample (up or down) to make it correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = pd.to_datetime(gdata['sim_start'])\n",
    "stop  = pd.to_datetime(gdata['sim_end'])\n",
    "\n",
    "tindex = pd.date_range(start, stop, freq='h')\n",
    "tindex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just set some values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infilt = pd.Series(0.10, index=tindex)                 # set the value of 0.10 at each timestep\n",
    "infilt['1976-03-01 01:00':'1976-11-01 05:00'] = 0.20   # overwrite for all datetimes in this interval (end points included)\n",
    "\n",
    "infilt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to the HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "infilt.to_hdf(hdfname, 'TIMESERIES/infilt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Second, add a row to the EXT_SOURCES table to send this time series to PERLND INFILT for segment P001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = pd.read_hdf(hdfname, '/CONTROL/EXT_SOURCES')\n",
    "nrows, ncols = ext.shape\n",
    "\n",
    "nrows, ncols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext.loc[nrows] = ['*', 'infilt', '', '', 1.0, '', 'PERLND', 'INFILT', '', 'P001', '', 'Adding New series to control infilt']\n",
    "ext.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ext.to_hdf(hdfname, '/CONTROL/EXT_SOURCES',  data_columns=True, format='table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HSP2tools.run_Tutorial(hdfname, saveall=True)\n",
    "#HSP2.run(hdfname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The infilt timeseries was found twice because it was made available to both SNOW and PWATER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire and Calculate Stats on Run 3 and Compare to Other Runs\n",
    "tsRun_3  = pd.read_hdf(hdfname, '/RESULTS/RCHRES_R001/HYDR')\n",
    "\n",
    "dfStats.Run3 = tsRun_3.RO.describe()\n",
    "dfStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample for Monthly Flow\n",
    "m_plt.figure(figsize=(16,8))\n",
    "m_plt.plot('RO', 'b--', data=tsMaster.resample('M').mean(),   label='Master')\n",
    "m_plt.plot('RO', 'r',   data=tsRun_1.resample('M').mean(),    label='Run1')\n",
    "m_plt.plot('RO', 'g',   data=tsRun_2.resample('M').mean(),    label='Run2')\n",
    "m_plt.plot('RO', 'k',   data=tsRun_3.resample('M').mean(),    label='Run3')\n",
    "\n",
    "m_plt.title('Flow at Reach 1')\n",
    "m_plt.ylabel('Monthly Flow {CFS}')\n",
    "m_plt.legend(loc='best') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MFACTOR and AFACTR, may replaced by a time series\n",
    "\n",
    "+ The MFACTOR table column is found in the MASS_LINK and EXT_SOURCES tables\n",
    "+ The AFACTR table column is found in the LINKS table\n",
    "\n",
    "If an AFACTR or MFACTOR element in a table is a string that starts with an asterisk, then the string after the asterisk is the name of a timeseries to be found in the HDF5 TIMESERIES directory.  It is treated as a sparse array and padded appropriately (aggregation method SAME).\n",
    "\n",
    "Otherwise, the AFACTOR or MFACTOR element should be a floating point number or string that can be converted into a floating point number. Internally, a timeseries is created with this value in every position.\n",
    "\n",
    "So either way, any AFACTOR or MFACTOR is a timeseries for internal calculation. They are multiplied pointwise times the data timeseries specified by the table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate a town growing and replacing  farm land during a simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This scenario is a town (IMPLND segment I001) growing over time replacing farm land (PERLND segment P001). The total area of the two segments must remain constant. This example uses the HSPF test10 HDF5, tutorial.h5.\n",
    "\n",
    "The total area of the two segments P001 and I001 is 9000 acres. \n",
    "\n",
    "The IMPLND area will increase linearly by 20% over the simulation period. That is the IMPLD segment will grow from 3000 to 3600 acres.\n",
    "This requires the PERLND segment to shrink from 6000 to 5400 acres.\n",
    "\n",
    "First, create a timeseries for IMPLND. Name it *implnd* and save in the HDF5 file.\n",
    "\n",
    "This process uses the tindex computed in the last example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "implnd = pd.Series(index=tindex)\n",
    "implnd[tindex[0]] = 3000.\n",
    "implnd[tindex[-1]] = 1.2 * 3000.\n",
    "implnd = implnd.interpolate(how='time')\n",
    "\n",
    "implnd.to_hdf(hdfname, 'TIMESERIES/implnd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a timeseries for PERLND\n",
    "\n",
    "Start with the original PERLND area and pointwise (in time) subtract the increase in the IMPLND segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "perlnd = 6000. - (implnd-3000.)         # Note: this is a full vector calculation\n",
    "\n",
    "perlnd.to_hdf(hdfname, 'TIMESERIES/perlnd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modify the AFACTR entries in the LINKS table\n",
    "\n",
    "It is necessary to indicate when and which time series will be used to replace a fixed AFACTR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf(hdfname, '/CONTROL/LINKS')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PERLND AFACTR is at table index 0, the IMPLND  AFACTR at index 5.\n",
    "\n",
    "Modify the AFACTR entries for these two rows and save back to the HDF5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0, 'AFACTR'] = '*perlnd'\n",
    "df.loc[5, 'AFACTR'] = '*implnd'\n",
    "df.AFACTR = df.AFACTR.astype(str)   # previously all entries were floats, so Pandas made this a float typed column.\n",
    "df.to_hdf(hdfname, '/CONTROL/LINKS',  data_columns=True, format='table')\n",
    "qgrid.disable()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the simulation and look for the message displayed whenever AFACTR is replaced by a time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HSP2tools.run_Tutorial(hdfname, saveall = 'True')\n",
    "#HSP2.run(hdfname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire and Calculate Stats on Run 4 and Compare to Other Runs\n",
    "tsRun_4  = pd.read_hdf(hdfname, '/RESULTS/RCHRES_R001/HYDR')\n",
    "\n",
    "dfStats.Run4 = tsRun_4.RO.describe()\n",
    "qgrid.show_grid(dfStats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample for Weekly Flow\n",
    "m_plt.figure(figsize=(16,8))\n",
    "m_plt.plot('RO', 'b--', data=tsMaster.resample('7D').mean(),   label='Master')\n",
    "m_plt.plot('RO', 'r',   data=tsRun_1.resample('7D').mean(),    label='Run1')\n",
    "m_plt.plot('RO', 'g',   data=tsRun_2.resample('7D').mean(),    label='Run2')\n",
    "m_plt.plot('RO', 'k',   data=tsRun_3.resample('7D').mean(),    label='Run3')\n",
    "m_plt.plot('RO', 'c',   data=tsRun_4.resample('7D').mean(),    label='Run4')\n",
    "\n",
    "m_plt.title('Flow at Reach 1')\n",
    "m_plt.ylabel('Monthly Flow {CFS}')\n",
    "m_plt.legend(loc='best') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"Images/HSP2.png\" />\n",
    "\n",
    "$\\textbf{HSP}^{\\textbf{2}}\\ \\text{and}\\ \\textbf{HSP2}\\ $ Copyright 2017 by RESPEC INC. and released under this [License](LegalInformation/License.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# INTRODUCTION: MIGRATION OF HSPF TO HSP2 and Running HSP2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This tutorial notebook demonstrates how to use legacy UCI and WDM files to create\n",
    "an HDF5 file for the new Python HSPF (HSP2). It shows how to use legacy PLTGEN files to plot results. Finally, it demonstrates at a high level the calibration process with HSP2 and IPython.\n",
    "\n",
    "**Tutorial Contents**\n",
    "\n",
    " + Legacy HSPF Migration and File Functionality\n",
    "     + Section 1: Importing UCI Files into HDF5\n",
    "     + Section 2: Importing WDM Files into HDF5\n",
    "     + Section 3: Importing PLTGEN Files and Pandas Module Functionality\n",
    " + Section 4: HSP2 Calibration Process\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Required Python imports  and setup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "##### Pandas is used for time series analysis, visualization, and interacting with the HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import site\n",
    "site.addsitedir(os.getcwd().rsplit('\\\\',1)[0] + '\\\\')  # adds your path to the HSP2 software.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows    = 18\n",
    "pd.options.display.max_columns = 10\n",
    "pd.options.display.float_format = '{:.3f}'.format  # display 3 digits after the decimal poin\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from wdmtoolbox import wdmutil\n",
    "\n",
    "import HSP2\n",
    "import HSP2tools\n",
    "HSP2tools.reset_tutorial()    # make a new copy of the tutorial's data\n",
    "HSP2tools.versions()          # display version information below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now that HSP2 is imported we can run the model and review the code through Introspection and Tab Completion to find the modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "HSP2.run?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Delete the documentation panel by clicking on its **X** in the upper right corner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Setup filenames\n",
    "Just for this preview Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "uciname = 'TutorialData/TEST10.UCI'          \n",
    "hdfname = 'TutorialData/tutorial.h5'\n",
    "wdmname = 'TutorialData/TEST.WDM'\n",
    "\n",
    "pltname = 'TutorialData/RCH900.6'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Note: make sure no HDF5 files exist at the start of this tutorial (since we want\n",
    "to make them here!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "!del TutorialData\\*.h5\n",
    "!dir TutorialData\\*.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Section 1: Importing UCI Files into HDF5<a id='section1'></a>\n",
    "\n",
    "HSPF was developed for a user input file (the UCI file) based on 80 column punch cards.\n",
    "The format of data on each card was specific to the type of data it contained.\n",
    "The sequence files for PERLND, IMPLND, and REACHES contain the format specifications to read the text file lines along\n",
    "with other information such as default values (for unspecified data), maximum and minimum limits per data element, message\n",
    "strings defining the meaning/use of each data element, and units type (English or Metric.)\n",
    "The UCI Reader uses these sequence files to parse the user's UCI file.\n",
    "\n",
    "The UCI Reader function currently is very nearly complete except for a few \"tables\" in the agri-chem modules that span multiple \"cards\".  These \"multiple cards\" are not yet combined into one table. These tables will be fixed when the associated HSPF modules are converted. \n",
    "\n",
    "A few data elements that are obsolete generate error messages to warn that they are being skipped.\n",
    "\n",
    "The UCI Reader will write its results to the specified HDF5 file. It will create the HDF5 file if necessary.\n",
    "If the HDF5 file already exists, it overwrites the UCI corresponding information.\n",
    "\n",
    "The HDF5 file includes the UCI file information (except obsolete elements) plus some new tables.  For example, there is now a SAVE table for each module in PERLND,\n",
    "IMPLND, and REACHES that specifies almost every computed timeseries and each segment. A one in the intersection\n",
    "of a named timeseries and a segment will save the results to the HDF5 file, otherwise it is not saved. This allows fine control for saving results for post run analysis. By default, only the output flux timeseries are saved.\n",
    "This tutorial shows how to save everything as an example of modifying the SAVE tables from the default.\n",
    "\n",
    "A few timeseries which can be trivially computed from the other timeseries are not explictly named or saved. The View Perlnd, View Implnd, and View Reaches notebooks provide examples of calculating the \"missing\" timeseries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Run the  UCI Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Run the UCI Reader\n",
    "The following shows the command to build the HSP2 HDF5 default file. This is a maintenance process and is discussed in the HSP2 Maintence Manual. It is shown for completeness, but is NOT intended to be executed in this tutorial.\n",
    "HSP2.makeH5(h2file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "HSP2tools.readUCI(uciname, hdfname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Use HDFView to examine the resulting HDF5 file. \n",
    "\n",
    "Some UCI tables not currently needed by HSP2 will be missing. They will be added when the associated HSPF modules are converted to HSP2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Section 2: Importing WDM Files into HDF5<a id='section2'></a>\n",
    "\n",
    "The WDM reader must be run after the UCI reader because it uses the EXT_SOURCES table from the HDF5 file to determine\n",
    "which timeseries to extract from the WDM file.\n",
    "\n",
    "For each timeseries named in the EXT_SOURCES table, the entire timeseries is extracted from the WDM file, truncated to the simulation's start and ending date/time, converted (aggregated/disaggregated) to the required simulation timestep, and saved in the specified HDF5 file. Its name is converted from a number to a string prefaced by \"TS\". The UCI reader has already adjusted all references to the timeseries datasets to use this naming convention.\n",
    "\n",
    "The WDM reader also extracts the metadata from the WDM file and attaches it to the timeseries group in the HDF5 file along with some other metadata.  Pandas also inserts its own metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### WDM Reader LICENSE and Copyright\n",
    "\n",
    "The UCI Reader uses Tim Cera's **wdmtoolbox**.  This code (version 0.8.2) was modified by RESPEC because HSPF UCI files that didn't contain a Constituent, Location, or Scenario attrributes will terminate with an error. Since the default HSPF test files don't have these attributes,  HSP2 can't run the test cases without this fix.\n",
    "\n",
    "Some later wdmtoolbox releases do not easily install under Windows, so this is the only version known to work.\n",
    "\n",
    "The wdmtoolbox is released under a GPL2 license and Tim Cera retains all rights to his module.\n",
    "\n",
    "The  wdmtoolbox is only used by the optional WDM Reader HSP2 module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Run the  WDM Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "HSP2tools.ReadWDM(wdmname, hdfname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Other tools for legacy files will be discussed in later Tutorials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Run test10\n",
    "Now show that this HDF5 file can run the HSPF Test10 simulation. The argument is the name of the HDF5 file containing all the information to define the run and to store the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "HSP2.run(hdfname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Note: The first time HSP2 is run, it takes a bit longer in order to perform a Just In Time, JIT, compilation.\n",
    "Soon, HSP2 will cache this compiled code so this step will only happen once. Currently, each time you start an HSP2 Notebook, the JIT function will happen\n",
    "\n",
    "Run this again to see the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "HSP2.run(hdfname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Section 3: HSP2 PLTGEN Functionality & Pandas Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**PLTGEN File Format Assumptions**\n",
    "\n",
    " + Text, not binary file\n",
    " + Initial 4 characters can be ignored in each line\n",
    " + First 25 lines are header information\n",
    " \n",
    "To find the column header information\n",
    "\n",
    " + The line containing the word \"LINTYP\" immediately proceeds the column header lines\n",
    " + The column headers stop at the first of\n",
    "     + line 26\n",
    "     + blank line (ignoring the first 4 characters)\n",
    "     + finding a line starting with \"Time series\" (ignoring the first 4 characters)\n",
    "\n",
    "To find the data (columns of time series data)\n",
    "\n",
    " + Line 26 is dummy data\n",
    " + Line 27 and on are actual lines with time series data\n",
    " + No entry is blank => all lines have the same number of entries (columns)\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df = HSP2tools.readPLTGEN(pltname)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Change column Headings to be shorter and Write to HDF5 File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.columns = ['RO', 'ROVOL', 'SSED', 'ROSED', 'TEMP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.to_hdf('pltgen.h5', 'RCH600', data_columns=True, format='table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_hdf('pltgen.h5','RCH600')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df['RO'].plot(label = 'simulated flow (cfs)',figsize = (18,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Accessing a column from the DataFrame (like above), produces a time series\n",
    "(Pandas Series). This allows resampling to other periods such as monthly and\n",
    "annually (as shown in Tutorial 3). The Pandas resampling methods include mean, sum, last, first, max, and min which cover the PLTGEN methods.  (PLTGEN AVER is Pandas mean.)  Pandas actually provides many more methods and allows user defined methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# resample to monthly mean flow\n",
    "df['RO'].resample('M').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# resample to annual mean, meadian, and standard deviation of flow\n",
    "dff = pd.DataFrame()\n",
    "dff['mean']   = df['RO'].resample('A').mean()\n",
    "dff['median'] = df['RO'].resample('A').median()\n",
    "dff['std']    = df['RO'].resample('A').std()\n",
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# resample for a time period and transform to 7-Day mean flow and then plot it \n",
    "df['RO']['1990-01-01' : '1995-06-30'].resample('7D').mean().plot(style='r--',figsize = (18,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Create a function and call it to plot mean annual average flow\n",
    "def ybar(df,label):\n",
    "    grouped = df.groupby(lambda x: x.year).mean().plot(kind='bar',figsize = (18,6))\n",
    "    plt.ylabel(label)\n",
    "    return grouped\n",
    "\n",
    "ybar( df['RO'],'cfs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Create a function and call it to plot mean monthly average flow\n",
    "def mbar(df,label):\n",
    "    grouped = df.groupby(lambda x: x.month).mean().plot(kind='bar',figsize = (18,6))\n",
    "    plt.ylabel(label)\n",
    "    return grouped\n",
    "\n",
    "mbar(df['RO'],'cfs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Section 4: HSP2 Calibration Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# review simulated flow from master hdf5 file prior to commencing calibration\n",
    "tsMaster = pd.read_hdf(hdfname, '/RESULTS/RCHRES_R001/HYDR')\n",
    "tsMaster.RO.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "simname  = 'SIM1'\n",
    "datapath = '/PERLND/PWATER/PARAMETERS'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Read the INFILT and LZSN values currently in hdfname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_hdf(hdfname, datapath)\n",
    "df[['INFILT', 'LZSN']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Make a copy of this data, modify the values for the new simulation run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfsim = df[['INFILT', 'LZSN']].copy()\n",
    "dfsim.INFILT = 0.3\n",
    "dfsim.LZSN = 12\n",
    "dfsim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Save just the modified sim data in a subdirectory named for the simulation. Note, the subdirectory is automatically created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfsim.to_hdf(hdfname, simname+datapath, data_columns=True, format='table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "It might be good to check how this looks in the HDF5 file using HDFView or Compass.\n",
    "\n",
    "Then run the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "HSP2.run(hdfname, simpath=simname, reload=True, saveall=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tsSim  = pd.read_hdf(hdfname, simname + '/RESULTS/RCHRES_R001/HYDR')\n",
    "tsSim.RO.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.plot('RO', 'b--', data=tsMaster, label='Master')\n",
    "plt.plot('RO', 'r',   data=tsSim,    label='Sim')\n",
    "plt.title('Flow at Reach 1')\n",
    "plt.ylabel('Flow {CFS}')\n",
    "plt.legend(loc='best') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Water - Fluxes (Exteral Inflows and Outflows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "path = '/RESULTS/PERLND_P001/PWATER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "dfperlnd1 = pd.read_hdf(hdfname, simname+path)\n",
    "dfperlnd1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The read returned all the data for PERLND1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Water - Fluxes (Exteral Inflows and Outflows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "dfwex = dfperlnd1.resample('M').sum()\n",
    "dfwex.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Sum the months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfsum = pd.DataFrame()\n",
    "dfsum['Annual Total']= dfwex.sum()\n",
    "dfsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# sum the months\n",
    "dfSum = pd.DataFrame()\n",
    "dfSum['Annual Total'] = dfwex.T.sum(axis=1)\n",
    "dfSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with open('print_example.txt', 'w') as f:\n",
    "    print >>f, dfwex.T\n",
    "    print\n",
    "    print >>f, dfSum\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%pycat print_example.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

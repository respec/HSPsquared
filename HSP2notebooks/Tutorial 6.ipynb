{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/HSP2.png\" />\n",
    "This Jupyter Notebook Copyright 2017 by RESPEC, INC.  All rights reserved.\n",
    "\n",
    "$\\textbf{HSP}^{\\textbf{2}}\\ \\text{and}\\ \\textbf{HSP2}\\ $ Copyright 2017 by RESPEC INC. and released under this [License](LegalInformation/License.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TUTORIAL 6: HSP$^2$ Watershed Network Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This tutorial will demonstrate the use of the watershed network tool.\n",
    "This tool can be used to\n",
    "\n",
    " + check the HSPF schematic and network data to find problems such as disconnected elements\n",
    " + (future) check that flux leaving a segment is balanced with flux entering other segments\n",
    " + create visual representations of the watershed network\n",
    " + create the simulation OP_SEQ\n",
    " + determine the smallest amount of recalculation required when simulation parameters are changed (SMART RUN)\n",
    " \n",
    " **Tutorial Contents**\n",
    "\n",
    " + Section 1: [Create a Watershed Network Graph](#section1)\n",
    " + Section 2: [Create an Operational Sequence (OP_SEQ)](#section2)\n",
    " + Section 3: [Create a Smart Operational Sequence](#section3)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Python imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import site\n",
    "site.addsitedir(os.getcwd().rsplit('\\\\',1)[0] + '\\\\')  # adds your path to the HSP2 software.\n",
    "\n",
    "hdfname = os.path.join('TutorialData', 'Tutorial.h5')\n",
    "\n",
    "import shutil\n",
    "import numpy as np\n",
    "from IPython.display import Image      # this displays graphic objects on this notebook\n",
    "import networkx\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows    = 18\n",
    "pd.options.display.max_columns = 10\n",
    "pd.options.display.float_format = '{:.2f}'.format  # display 2 digits after the decimal point\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    " \n",
    "import HSP2\n",
    "import HSP2tools\n",
    "\n",
    "HSP2tools.reset_tutorial()    # make a new copy of the tutorial's data\n",
    "HSP2tools.versions()          # display version information below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Create a Watershed Network Graph<a id='section1'></a>\n",
    "\n",
    "The watershed flow network is mathematically a Directed Acyclic Graph (DAG).\n",
    "This tool creates a DAG from the $\\textbf{HSP}^\\textbf{2}$ NETWORK, SCHEMATIC, and MASS_LINK tables using a graph algorithm library, networkx.\n",
    "\n",
    "The networkx library can apply many graph algorithms\n",
    "to the DAG which are useful in watershed modelling to check the integrity of the watershed model. This checking would be vastly more powerful if Geographic Information is available to provide shapefiles, areas, elevations, slopes and coordinates (such as the shapefile centroid's coordinates for each segment. This information can be stored in the HDF5 file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Problems in the watershed's DAG\n",
    "This routine checks to insure that the watershed's graph is a proper DAG. That is, it looks for disconnected segments and loops.\n",
    "\n",
    "**Note:** Additional types of checking will be added soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HSP2tools.check_network(hdfname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Display the watershed's DAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For this example, some additional information will be put into the HDF5 file to simulate adding GIS information that can be used by this tool. First, review the information in the RCHRES GENERAL_INFO table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf(hdfname, '/RCHRES/GENERAL_INFO')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now add some (fake) data to the GENERAL_INFO tables for PERLND, IMPLND, and RCHRES.\n",
    "+ GISarea would be the segment's area computed from GIS shapefiles or other sources.\n",
    "+ GISx and GISy represent scaled coordinates of the the segment (perhaps as represented by the coordinates of the segment's centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HSP2tools.graphtutoral_test10(hdfname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check that new data is available in the HDF5 file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf(hdfname, '/RCHRES/GENERAL_INFO')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will read the PERLND, IMPLND, and RCHRES GENERAL_INFO tables. It will build Python dictionaries for that colors and coordinates that it found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dcolor = {}\n",
    "dpositions = {}\n",
    "\n",
    "operations = ['PERLND', 'IMPLND', 'RCHRES']\n",
    "for operation in operations:\n",
    "    for i,r in pd.read_hdf(hdfname, operation + '/GENERAL_INFO').iterrows():\n",
    "        name = operation + '\\n' + i\n",
    "        dcolor[name]     = r.GIScolor\n",
    "        dpositions[name] = (r.GISx, r.GISy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build the DAG for the test10 watershed. \n",
    "\n",
    "The sep argument will split the long name to fit into the graph better. It is optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = HSP2tools.graph_fromHDF(hdfname, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell builds a list of colors from DAG nodes used to look up the color in the dcolor dictionary above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [dcolor[x] for x in dg.nodes()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now view the DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,10])\n",
    "plt.axis('off')\n",
    "\n",
    "networkx.draw_networkx(dg, pos=dpositions, node_color=colors, node_size=4500, node_shape='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DAG shows the connectivity of the watershed, but more can be done.\n",
    "the code created the DAG, it also looked for the RCHRES segments that had no decendents, segments that had no predecessor, or had neither. It marked those nodes with special colors to make this visible in the network graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for node in dg.nodes():\n",
    "    dagcolor = dg.node[node]['fillcolor']\n",
    "    if dagcolor:\n",
    "        dcolor[node] = dagcolor\n",
    "colors = [dcolor[x] for x in dg.nodes()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,10])\n",
    "plt.axis('off')\n",
    "\n",
    "networkx.draw_networkx(dg, pos=dpositions, node_color=colors, node_size=4500, node_shape='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gold colored square identifies a RCHRES that does not feed into another segment. A red colored node would be an isolated node (no predecessor nor successor nodes). A dark green square would be a RCHRES with no predecessor flowing into it.\n",
    "\n",
    "If GIS area and elevation data were available, it would be easy to extend the tool to perform more rigorous checking of the watershed network model.\n",
    "\n",
    "The hardest problem with viewing network graphs is to create a layout that is informative.  The use of GIS information allows the network graph to be layed out using GIS coordinates. The network graph can even be viewed on top of maps showing streets and other topological features.\n",
    "\n",
    "The networkx library allows an arbitrary amount of information to be attached to each node and connecting edge. The network tool sets properties on the node like optype (PERLND, IMPLND or RCHRES) and segment (R004) to assist this process.\n",
    "\n",
    "Unfortunately, network graph viewers are operationg system dependent and fall outside this tutorial.\n",
    "In general, network graph viewers look for names specific to the viewer to set properties such as edge labels, node labels, node shape, node colors, etc. So you can write a small piece of code to set these required node properties and then write out the file in a format that can be read by your viewer (using the networkx write functions.)\n",
    "\n",
    "\n",
    "Assume the network graph viewer you selected uses the node property named *shape* with options like 'square', 'circle', and 'diamond'. You desire to change the node shape based on the associated opertion.\n",
    "\n",
    "Then code like the following can set this property based on the node's optype (set by this tool):\n",
    "\n",
    "```\n",
    "for node in dg.nodes:\n",
    "   if dg.nodes[node]['optype'] == 'PERLND':\n",
    "       dg.nodes[node]['shape'] =  'square'\n",
    "   elif dg.nodes[node]['optype'] == 'IMPLND':\n",
    "       dg.nodes[node]['shape'] = 'diamond'\n",
    "   elif dg.nodes[node]['optype'] == 'RCHRES':\n",
    "       dg.nodes[node]['shape'] = 'circle'\n",
    "```\n",
    "\n",
    "Then use a one of the many networkx routines to write the DAG for  your viewer. For example, to write the graph as a GraphML format you would do\n",
    "```\n",
    "networkx.write_graphml(df, \"test.graphml\")\n",
    "```\n",
    "\n",
    "Then your network graph viewer can display your watershed's DAG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Section Summary**\n",
    "\n",
    " + Demonstrated making a Directed Acyclic Graph representing the flows in a watershed from the HDF5 file\n",
    " + Demonstrated checking the watershed model for disconnected elements\n",
    " + Demonstrated converting the graph into a variety of formats\n",
    "     + PDF\n",
    "     + JPEG\n",
    "     + SVG\n",
    "     + PNG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Create an Operational Sequence (OP_SEQ) table<a id='section2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DAG can be used to create the OP_SEQ table which is then be saved into the HDF5 file to be used in the simulation. Mathematically, the DAG is sorted with a topological sort algorithm.\n",
    "\n",
    "Start by deleting the OP_SEQUENCE table from **tutorial.h5**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.get_store(hdfname) as store:\n",
    "    del store['/CONTROL/OP_SEQUENCE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now show the error when trying to read the OP_SEQUENCE table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_hdf(hdfname, '/CONTROL/OP_SEQUENCE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the utility to make an operational sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HSP2tools.make_opseq(hdfname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### View the OP_SEQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.read_hdf(hdfname, '/CONTROL/OP_SEQUENCE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run the simulation to check that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HSP2.run(hdfname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Create a \"Smart Run\" Operational Sequence<a id='section3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use Case** Rerun the smallest number of operations for simulation.\n",
    "\n",
    "Many times a simulation will be rerun with changes to only some of the watershed's data.\n",
    "The \"SMART RUN\" capability creates an OP_SEQ which only performs the minimum set of operations to save run time.\n",
    "\n",
    "Copy the tutorial.h5 file to make master.h5 and sim1.h5 files for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master = os.path.join('TutorialData', 'master.h5')\n",
    "sim1 = os.path.join('TutorialData', 'sim1.h5')\n",
    "\n",
    "shutil.copyfile(hdfname, master)\n",
    "shutil.copyfile(hdfname, sim1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The master file will be the fixed watershed reference.\n",
    "\n",
    "First, check what happens with no changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HSP2tools.smart_opseq(master, sim1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sim1 HDF5 file represents one of the HDF5 files you would create while analyzing the watershed.\n",
    "Now make a change to the **sim1.h5** file as if you were exploring the impact of changing a parameter.\n",
    "\n",
    "(This works with any number of changes to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_hdf(sim1, '/RCHRES/HYDR/STATE')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc['R003', 'VOL'] = 5  \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the change to the **sim.h5** HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_hdf(sim1, '/RCHRES/HYDR/STATE', data_columns=True, format='table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that there is at least one difference between the master and sim HDF5 files, we can \n",
    "determine the minimum simulation run (assuming all previous results are available when needed.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Smart Operation Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HSP2tools.smart_opseq(master, sim1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check to see what the new OP_SEQ table looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.read_hdf(sim1, '/CONTROL/OP_SEQUENCE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OP_SEQUENCE table shows that only a subset of the watershed network must be rerun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the simulation with the Smart OPSEQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HSP2.run(sim1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, **smart_opseq**  checks every table under the \"/PERLND\", \"/IMPLND\" and \"/RCHRES\" directories in the HDF5, and the NETWORK, SCHEMATIC, and EXT_SOURCES tables to determine\n",
    "which segments need to be rerun. (Even tables added by the user.) It automatically reruns all segments \"down stream\" from the\n",
    "changed segments.  Any change is considered significant.\n",
    "\n",
    "It can be extended to check the other tables such as the MASS_LINK table if desired.\n",
    "\n",
    "#### Tutorial 7 discusses a more advanced capability for the smart_opseq."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Section Summary**\n",
    "\n",
    " + Demonstrate creating the **OP_SEQ** table from schematic, network, and mass link tables\n",
    " + Demonstrated **SMART RUN** to create the minimal calculation **OP_SEQ** table when some simulation parameters are changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
